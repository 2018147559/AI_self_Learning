{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn #많은 neural network이 담겨있는 모듈입니다. \nimport torch.optim as optim  # 많은 optimizer가 담겨있는 모듈입니다. \nimport torch.nn.init as init # neural network를 초기화 하는 모듈을 담고 있습니다. \nfrom torch.utils.data import DataLoader # DataLoader는 데이터를 batch_size만큼 불러오는 역할 등을 수행합니다. \nimport torchvision \nimport torchvision.datasets as dset # 사진 등의 vision 데이터가 담겨있는 모듈입니다. \nimport torchvision.transforms as transforms #이 모듈에는 데이터를 자르고, 반전시키고 tensor로 변환해주기 등의 데이터 변환 함수가 담겨있습니다.  드\nimport numpy as np\nimport os \nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import ImageFolder\nprint(torch.__version__)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-26T05:35:19.180502Z","iopub.execute_input":"2021-08-26T05:35:19.180845Z","iopub.status.idle":"2021-08-26T05:35:19.188326Z","shell.execute_reply.started":"2021-08-26T05:35:19.180809Z","shell.execute_reply":"2021-08-26T05:35:19.187350Z"},"trusted":true},"execution_count":235,"outputs":[{"name":"stdout","text":"1.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"path = '../input/chest-xray-pneumonia/chest_xray/'\nmean = torch.tensor([0.4822])\nstd = torch.tensor([0.2328])\ntransformations = transforms.Compose([transforms.Resize((64,64)), \n                              transforms.ToTensor(), \n                              transforms.Normalize(mean, std),\n                             ])","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.190085Z","iopub.execute_input":"2021-08-26T05:35:19.190518Z","iopub.status.idle":"2021-08-26T05:35:19.203179Z","shell.execute_reply.started":"2021-08-26T05:35:19.190480Z","shell.execute_reply":"2021-08-26T05:35:19.202259Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"train = ImageFolder(os.path.join(path, 'train'), transform=transformations, target_transform=lambda x:np.reshape(np.float32(x),(1)))\nval = ImageFolder(os.path.join(path, 'val'), transform=transformations, target_transform=lambda x:np.reshape(np.float32(x),(1)))\ntest = ImageFolder(os.path.join(path, 'test'), transform=transformations)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.204882Z","iopub.execute_input":"2021-08-26T05:35:19.205516Z","iopub.status.idle":"2021-08-26T05:35:19.263025Z","shell.execute_reply.started":"2021-08-26T05:35:19.205477Z","shell.execute_reply":"2021-08-26T05:35:19.262021Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"print(train.__getitem__(0)[0].size(), train.__len__())\nprint(test.__getitem__(0)[0].size(), test.__len__())\n\nprint(len(train),len(test))\nprint(train[0][0][1])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.267477Z","iopub.execute_input":"2021-08-26T05:35:19.269592Z","iopub.status.idle":"2021-08-26T05:35:19.461765Z","shell.execute_reply.started":"2021-08-26T05:35:19.269548Z","shell.execute_reply":"2021-08-26T05:35:19.460635Z"},"trusted":true},"execution_count":238,"outputs":[{"name":"stdout","text":"torch.Size([3, 64, 64]) 5216\ntorch.Size([3, 64, 64]) 624\n5216 624\ntensor([[-1.7344, -1.5996, -1.0437,  ...,  0.2533, -0.4205, -0.4879],\n        [-1.7344, -1.7007, -1.1617,  ..., -0.0499, -0.4879, -0.5384],\n        [-1.7176, -1.7512, -1.2964,  ..., -0.3194, -0.5215, -0.6058],\n        ...,\n        [-1.5996, -1.5996, -1.6333,  ..., -1.7176, -1.7007, -1.6839],\n        [-1.5996, -1.6165, -1.6333,  ..., -1.6165, -1.5996, -1.5828],\n        [-1.4986, -1.5154, -1.5323,  ..., -0.9258, -0.8921, -0.8584]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 하이퍼 파라미터","metadata":{}},{"cell_type":"code","source":"#CNN에서 대표적인 하이퍼 파라미터로는  num_epoch, batch_size, learnin_rate가 있습니다. 이는 모델에 따라 가감될 수 있습니다. \nnum_epoch=10\nbatch_size=256\nlearning_rate= 0.0002","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.466283Z","iopub.execute_input":"2021-08-26T05:35:19.468458Z","iopub.status.idle":"2021-08-26T05:35:19.476017Z","shell.execute_reply.started":"2021-08-26T05:35:19.468361Z","shell.execute_reply":"2021-08-26T05:35:19.474860Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 로더","metadata":{}},{"cell_type":"code","source":"#위에서 데이터를 정의했는데 왜 또 데이터를 정의하나요? 라는 의문이 생길 것 같습니다. \n#위에서는 데이터 전부를 정의했습니다. mnist_train에는 모든 학습 데이터가 들어있습니다.\n#모든 학습 데이터를 한 번에 학습하면 과부하가 발생할 것입니다. \n#그래서 데이터를 조금씩 조금씩 쪼개서 학습할 필요가 있습니다. 그 역할을 수행하는 것이 DataLodaer이고 때문에 여기서 train_loader,text_loader를 정의하는 것입니다. \ntrain_loader=DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=2,drop_last=True)\ntest_loader=DataLoader(dataset=test,batch_size=batch_size,shuffle=False,num_workers=2,drop_last=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.482902Z","iopub.execute_input":"2021-08-26T05:35:19.485340Z","iopub.status.idle":"2021-08-26T05:35:19.493876Z","shell.execute_reply.started":"2021-08-26T05:35:19.485299Z","shell.execute_reply":"2021-08-26T05:35:19.492804Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"markdown","source":"# 모델\nConv(1,16,5)->ReLu->Conv(16,32,5)->ReLu->MaxPool2d(2,2)->Conv2d(32,64,5)->ReLu->MaxPool2d(2,2)->fc","metadata":{}},{"cell_type":"code","source":"#모델을 정의할 때 유념해야할 건 각 층의 결과물의 사이즈입니다. \n#이 층에서 어떤 size를 가진 데이터를 몇 개 도출하는지 정확하게 알고 있어야 정확한 모델을 정의할 수 있습니다. \n#모델이 복잡해지면 복잡해질수록 이는 더욱 중요해집니다. 때문에 모델을 정의할 때 옆에 각 모델이 도출하는 데이터의 크기를 써넣는 것을 추천드립니다. \n#해당 모델은 임의로 만든 모델입니다. 이 모델이 다른 모델보다 뛰어나다는 보장이 없습니다. \nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN,self).__init__()\n        self.layer = nn.Sequential(\n            nn.Conv2d(in_channels=3,out_channels=16,kernel_size=5),             # [batch_size,1,64,64] -> [batch_size,16,60,60]\n            #nn.BatchNorm2d(16),\n            nn.ReLU(),                                                          # 필터의 개수는 1개(흑백이미지)에서 16개로 늘어나도록 임의로 설정했습니다. \n            #nn.Dropout2d(0.5),\n            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),            # [batch_size,16,60,60] -> [batch_size,32,56,56]\n            #nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Dropout2d(0.1),\n            nn.MaxPool2d(kernel_size=2,stride=2),                               # [batch_size,32,56,56] -> [batch_size,32,28,28]\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),          # [batch_size,32,28,28] -> [batch_size,64,24,24]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Dropout2d(0.3),\n            nn.MaxPool2d(kernel_size=2,stride=2)                                # [batch_size,64,24,24] -> [batch_size,64,12,12]\n        )\n        self.fc_layer = nn.Sequential(                                          \n            nn.Linear(64*12*12,10),                                              # [batch_size,64*12*12] -> [batch_size,10]\n            nn.ReLU(),\n            nn.Linear(10,1),                                                   # [batch_size,10] -> [batch_size,1]\n            nn.Sigmoid()\n        )       #Initialization. \n      # 초기화 하는 방법\n        # 모델의 모듈을 차례대로 불러옵니다.\n        for m in self.modules():\n            # 만약 그 모듈이 nn.Conv2d인 경우\n            if isinstance(m, nn.Conv2d):\n                '''\n                # 작은 숫자로 초기화하는 방법\n                # 가중치를 평균 0, 편차 0.02로 초기화합니다.\n                # 편차를 0으로 초기화합니다.\n                m.weight.data.normal_(0.0, 0.02)\n                m.bias.data.fill_(0)\n                \n                # Xavier Initialization\n                # 모듈의 가중치를 xavier normal로 초기화합니다.\n                # 편차를 0으로 초기화합니다.\n                init.xavier_normal(m.weight.data)\n                m.bias.data.fill_(0)\n                '''\n                \n                # Kaming Initialization\n                # 모듈의 가중치를 kaming he normal로 초기화합니다.\n                # 편차를 0으로 초기화합니다.\n                init.kaiming_normal_(m.weight.data)\n                m.bias.data.fill_(0)\n            \n            # 만약 그 모듈이 nn.Linear인 경우\n            elif isinstance(m, nn.Linear):\n                '''\n                # 작은 숫자로 초기화하는 방법\n                # 가중치를 평균 0, 편차 0.02로 초기화합니다.\n                # 편차를 0으로 초기화합니다.\n                m.weight.data.normal_(0.0, 0.02)\n                m.bias.data.fill_(0)\n                \n                # Xavier Initialization\n                # 모듈의 가중치를 xavier normal로 초기화합니다.\n                # 편차를 0으로 초기화합니다.\n                init.xavier_normal(m.weight.data)\n                m.bias.data.fill_(0)\n                '''\n                \n#                 # Kaming Initialization\n#                 # 모듈의 가중치를 kaming he normal로 초기화합니다.\n#                 # 편차를 0으로 초기화합니다.\n#                 init.kaiming_normal_(m.weight.data)\n#                 m.bias.data.fill_(0)\n        \n    \n    def forward(self,x):\n        out = self.layer(x)                                                     # self.layer에 정의한 Sequential의 연산을 차례대로 다 실행합니다.\n        out=out.view(batch_size,-1)                                           # view 함수를 이용해 텐서의 형태를 [batch_size,나머지]로 바꿔줍니다. \n                                                                                # ex) 2x3 형태였던 텐서를 .view(1,-1) 해주면 1x6의 형태로 바뀝니다. .view(3,-1)이면 3x2로 바뀜.\n                                                                                # 만약 전체 텐서의 크기가 batch_size로 나누어 떨어지지 않으면 오류가 납니다.\n        out = self.fc_layer(out)\n        return out\n    def summary(self):\n        self.summary()\n        \n# https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d\n# https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view\n\n\n\n\n  ","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.500063Z","iopub.execute_input":"2021-08-26T05:35:19.503085Z","iopub.status.idle":"2021-08-26T05:35:19.523733Z","shell.execute_reply.started":"2021-08-26T05:35:19.503045Z","shell.execute_reply":"2021-08-26T05:35:19.522716Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"# 손실함수","metadata":{}},{"cell_type":"code","source":"#gpu나 cpu를 device로 불러들입니다. 그리고 device에서 학습이 진행되게끔 모델을 device에 올려놓습니다.\n#loss function과 optimizer를 정의하는 것도 잊지 마세요! \n#우리는 torch가 제공하는 걸 가져다 쓰면 됩니당 ~ ^_^  \ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')  \n\nprint(device)\n\nmodel=CNN().to(device)\n\nloss_func=nn.BCELoss()\n\noptimizer=torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay = 0.05)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.528676Z","iopub.execute_input":"2021-08-26T05:35:19.531424Z","iopub.status.idle":"2021-08-26T05:35:19.552161Z","shell.execute_reply.started":"2021-08-26T05:35:19.531384Z","shell.execute_reply":"2021-08-26T05:35:19.551273Z"},"trusted":true},"execution_count":242,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 학습!!","metadata":{}},{"cell_type":"code","source":"loss_arr=[]\nfor i in range(num_epoch):\n    model.train()\n    for j,[image,label] in enumerate(train_loader):  #아래에서 j를 이용해서 loss를 모으기 위해 이렇게 코드를 짰습니다.\n        x= image.to(device)            #학습이미지와 \n        y_=label.to(device)           #정답을 device에 올려놓습니다.\n        optimizer.zero_grad() \n        output=model.forward(x)       #학습이미지를 모델에 돌린 결과를 가져옵니다. \n        loss=loss_func(output,y_)     #결과와 정답을 loss function에 넣고 loss를 추출합니다. \n        loss.backward()               #추출된 loss를 통해 역전파 ! \n        optimizer.step()              #역전파를 했다면 optimizer.step()를 통해 파라미터를 이동시켜줍시다. \n\n        if j%1000==0:\n          print(loss)\n          loss_arr.append(loss.cpu().detach().numpy())\n\n    correct=0\n    total=0    \n    model.eval()\n    with torch.no_grad():\n        for ige,lel in test_loader:\n            x=ige.to(device)\n            y_=lel.to(device)\n            output=model.forward(x)\n             #https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max\n            #_,output_index=torch.max(torch.round(output),1)  #max함수는 max value와 max value의 index를 도출합니다. 두 번째 인자 1은 결과의 dimension을 의미합니다. \n\n            total+=lel.size(0)\n\n            correct += (torch.round(output.view(-1, batch_size))==y_).sum().float()\n    print(\"Accuracy of Test Data: {}%\".format(100 * correct/total))\n    \n\n\n\n        \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:35:19.555985Z","iopub.execute_input":"2021-08-26T05:35:19.557928Z","iopub.status.idle":"2021-08-26T05:46:52.465556Z","shell.execute_reply.started":"2021-08-26T05:35:19.557854Z","shell.execute_reply":"2021-08-26T05:46:52.464622Z"},"trusted":true},"execution_count":243,"outputs":[{"name":"stdout","text":"tensor(0.6245, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 72.4609375%\ntensor(0.2360, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 72.0703125%\ntensor(0.1837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 73.6328125%\ntensor(0.1670, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 71.875%\ntensor(0.0948, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 67.1875%\ntensor(0.1151, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 73.6328125%\ntensor(0.0911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 74.8046875%\ntensor(0.0852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 75.0%\ntensor(0.1087, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 70.8984375%\ntensor(0.0577, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\nAccuracy of Test Data: 68.359375%\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(loss_arr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:46:52.467078Z","iopub.execute_input":"2021-08-26T05:46:52.467371Z","iopub.status.idle":"2021-08-26T05:46:52.648577Z","shell.execute_reply.started":"2021-08-26T05:46:52.467336Z","shell.execute_reply":"2021-08-26T05:46:52.647644Z"},"trusted":true},"execution_count":244,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# 마무리 테스트!","metadata":{}},{"cell_type":"code","source":"correct=0\ntotal=0\nmodel.eval()\nwith torch.no_grad():\n    for image,label in test_loader:\n        x=image.to(device)\n        y_=label.to(device)\n        output=model.forward(x)\n     #https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max\n        _,output_index=torch.max(output,1)  #max함수는 max value와 max value의 index를 도출합니다. 두 번째 인자 1은 결과의 dimension을 의미합니다. \n\n        total+=label.size(0)\n\n        correct += (torch.round(output.view(-1, batch_size))==y_).sum().float()\n        print(torch.round(output.view(-1, batch_size)))\n        print(y_)\nprint(\"Accuracy of Test Data: {}%\".format(100*correct/total))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T05:46:52.650010Z","iopub.execute_input":"2021-08-26T05:46:52.650593Z","iopub.status.idle":"2021-08-26T05:47:00.058282Z","shell.execute_reply.started":"2021-08-26T05:46:52.650555Z","shell.execute_reply":"2021-08-26T05:47:00.057255Z"},"trusted":true},"execution_count":245,"outputs":[{"name":"stdout","text":"tensor([[1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n         0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n         1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n         1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n         0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n         1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n         0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n         1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n         1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1.]], device='cuda:0')\ntensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\ntensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1.]], device='cuda:0')\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\nAccuracy of Test Data: 68.359375%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 결과 : 아쉽게도 맞출 확률은 75.6퍼여서 좀더 조정이 필요함, 제출후 한번 생각해보겠음","metadata":{}}]}